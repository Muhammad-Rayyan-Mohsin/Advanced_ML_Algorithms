{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "n-QxxuW90bO_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df_Original = df.copy()\n",
        "df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "gVyWhKOi0i2W"
      },
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LEvDmfVWaCh",
        "outputId": "e10251e1-3627-4923-c4cc-8ef7e71eccfb"
      },
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    object \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['diagnosis'] = le.fit_transform(df['diagnosis'])"
      ],
      "metadata": {
        "id": "osiHWCU81Ans"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['texture_se', 'symmetry_se', 'fractal_dimension_se'], axis=1, inplace=True)\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "s8Nkf6YBIng5"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "# Function to print all relevant metrics\n",
        "def print_metrics(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Initialize and fit the XGBoost model\n",
        "xgb_model = XGBClassifier(n_estimators=3, max_depth=4, learning_rate=0.8, objective='binary:logistic')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "print_metrics(y_test, xgb_preds, \"XGBoost\")\n",
        "\n",
        "# Initialize and fit the LightGBM model\n",
        "lgbm_model = LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "lgbm_preds = lgbm_model.predict(X_test)\n",
        "lgbm_preds\n",
        "print_metrics(y_test, lgbm_preds, \"LightGBM\")\n",
        "\n",
        "# Initialize and fit the Bagging Classifier model\n",
        "base_classifier = LogisticRegression(solver='liblinear')\n",
        "bagging_classifier = BaggingClassifier(base_estimator=base_classifier, n_estimators=10, random_state=123)\n",
        "cv_scores = cross_val_score(bagging_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(f'Bagging Classifier Mean Accuracy (Cross-Validation): {mean_cv_score:.2f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaG1HQVX1SqC",
        "outputId": "abc768e3-6151-4f74-d682-a5ae4ffebf62"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Metrics:\n",
            "Accuracy: 0.9561\n",
            "Precision: 0.9524\n",
            "Recall: 0.9302\n",
            "F1 Score: 0.9412\n",
            "Confusion Matrix:\n",
            "[[69  2]\n",
            " [ 3 40]]\n",
            "------------------------------\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 169, number of negative: 286\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4092\n",
            "[LightGBM] [Info] Number of data points in the train set: 455, number of used features: 27\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.371429 -> initscore=-0.526093\n",
            "[LightGBM] [Info] Start training from score -0.526093\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Metrics:\n",
            "Accuracy: 0.9737\n",
            "Precision: 0.9762\n",
            "Recall: 0.9535\n",
            "F1 Score: 0.9647\n",
            "Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 2 41]]\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Mean Accuracy (Cross-Validation): 0.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Bagging Classifier Mean Accuracy (Cross-Validation): 0.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Bagging Classifier Mean Accuracy (Cross-Validation): 0.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Nearest Neighbors Bagging Classifier Mean Accuracy (Cross-Validation): 0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**- Blending**\n",
        "\n",
        "---\n",
        "**Stacked Model**: An ensemble of models in which the meta-model is trained on out-of-fold predictions made by the base models during k-fold cross validation.\n",
        "\n",
        "**Blended Model**: An ensemble of models in which the meta-model is trained on predictions made by the base models on a holdout dataset (e.g., the validation dataset).\n"
      ],
      "metadata": {
        "id": "2c1I9JlMiMSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=12345)"
      ],
      "metadata": {
        "id": "VM5r4i0LdbZ5"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [('dtc', DecisionTreeClassifier()),\n",
        "        ('gnb', ExtraTreesClassifier()),\n",
        "        ('ada', AdaBoostClassifier()),\n",
        "        ('rf', RandomForestClassifier())]"
      ],
      "metadata": {
        "id": "rgTBWlM0VVhg"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_models(models, X_train, X_valid, y_train, y_valid):\n",
        "\n",
        "    #Create variable in which to store predictions for meta-model.\n",
        "    preds_for_meta = []\n",
        "\n",
        "    #Loop through models in model list.\n",
        "    for name, model in tqdm(models):\n",
        "\n",
        "        #Fit model and obtain predictions.\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "        #Obtain base moedl roc score.\n",
        "        roc_base = roc_auc_score(y_valid, pred)\n",
        "\n",
        "        print(f'{model} score: {roc_base}')\n",
        "\n",
        "        #Reshape prediction into single-column matrix.\n",
        "        pred = pred.reshape(len(pred), 1)\n",
        "\n",
        "        #Append prediction to varible for meta-model.\n",
        "        preds_for_meta.append(pred)\n",
        "\n",
        "    #Create 2D array from predictions.\n",
        "    meta_features = np.hstack(preds_for_meta)\n",
        "\n",
        "    #Define blender for model.\n",
        "    meta_model = xgb.XGBClassifier(n_estimators=7000,\n",
        "                                 #tree_method='gpu_hist',\n",
        "                                 #gpu_id = 0,\n",
        "                                 random_state = 5,\n",
        "                                 learning_rate=.03)\n",
        "\n",
        "    #Fit meta model on predictions from base models.\n",
        "    meta_model.fit(meta_features, y_valid.values.ravel(),\n",
        "                 verbose=False,\n",
        "                 eval_set=[(meta_features, y_valid.values.ravel())],\n",
        "                 eval_metric='auc',\n",
        "                 early_stopping_rounds=300)\n",
        "\n",
        "    print(f'Meta AUC: {roc_auc_score(y_valid, meta_model.predict_proba(meta_features)[:, 1])}')\n",
        "\n",
        "    return meta_model\n",
        "\n",
        "def meta_predict(models, meta_model, X_test, threshold=0.5):\n",
        "    preds_for_meta = []\n",
        "\n",
        "    for name, model in tqdm(models):\n",
        "        pred = model.predict(X_test)\n",
        "\n",
        "        pred = pred.reshape(len(pred), 1)\n",
        "\n",
        "        preds_for_meta.append(pred)\n",
        "\n",
        "    meta_features = np.hstack(preds_for_meta)\n",
        "\n",
        "    meta_preds = meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "    binary_preds = (meta_preds >= threshold).astype(int)\n",
        "\n",
        "    return binary_preds\n"
      ],
      "metadata": {
        "id": "leCKefu2aOuM"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_model = fit_models(models, X_train, X_valid, y_train, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXdP1DQ9aYPF",
        "outputId": "6d61460b-322c-494c-b62c-b84861e374b9"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 1/4 [00:00<00:00,  7.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier() score: 0.9238064791133844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [00:00<00:01,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExtraTreesClassifier() score: 0.9858269394714407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:01<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoostClassifier() score: 0.9731457800511509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier() score: 0.9748508098891732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_pred = meta_predict(models, meta_model, X_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muD02damafeM",
        "outputId": "08c195d3-f7c2-409d-fae7-34a6c626a2a0"
      },
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 101.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAjARc8Db-Fo",
        "outputId": "f12f8485-c450-4575-c1f3-35e3087bac3c"
      },
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Classifier\n",
        "\n",
        "---\n",
        "- Using RF, LR and DT\n"
      ],
      "metadata": {
        "id": "VfxHcqi9xnCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # with the following function we can select highly correlated features\n",
        "# # it will remove the first feature that is correlated with anything other feature\n",
        "\n",
        "# def correlation(dataset, threshold):\n",
        "#     col_corr = set()  # Set of all the names of correlated columns\n",
        "#     corr_matrix = dataset.corr()\n",
        "#     for i in range(len(corr_matrix.columns)):\n",
        "#         for j in range(i):\n",
        "#             if corr_matrix.iloc[i, j] > threshold: # we are interested in absolute coeff value\n",
        "#                 colname = corr_matrix.columns[i]  # getting the name of column\n",
        "#                 col_corr.add(colname)\n",
        "#     return col_corr\n",
        "\n",
        "# corr_features = correlation(X_train, 0.7)\n",
        "\n",
        "# print(len(set(corr_features)))\n",
        "\n",
        "# print(corr_features)\n",
        "\n",
        "# #Effect\n",
        "# X_train.drop(corr_features,axis=1, inplace=True)\n",
        "# X_test.drop(corr_features,axis=1, inplace=True)\n",
        "# X_train.columns\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thres=VarianceThreshold(threshold=0.7)\n",
        "var_thres.fit(X_train)\n",
        "print(var_thres.get_support())\n",
        "sum(var_thres.get_support())\n",
        "selected_features = X_train.columns[var_thres.get_support()]\n",
        "print(selected_features)\n",
        "\n",
        "constant_columns = [column for column in X_train.columns\n",
        "                    if column not in X_train.columns[var_thres.get_support()]]\n",
        "\n",
        "print(\"Number of columns to be eliminated: \", len(constant_columns))\n",
        "for column in constant_columns:\n",
        "    print(column)\n",
        "\n",
        "#Effect\n",
        "X_train.drop(constant_columns,axis=1, inplace=True)\n",
        "X_test.drop(constant_columns,axis=1, inplace=True)\n",
        "X_train.columns\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thres=VarianceThreshold(threshold=0.7)\n",
        "var_thres.fit(X_train)\n",
        "print(var_thres.get_support())\n",
        "sum(var_thres.get_support())\n",
        "selected_features = X_train.columns[var_thres.get_support()]\n",
        "print(selected_features)\n",
        "\n",
        "constant_columns = [column for column in X_train.columns\n",
        "                    if column not in X_train.columns[var_thres.get_support()]]\n",
        "\n",
        "print(\"Number of columns to be eliminated: \", len(constant_columns))\n",
        "for column in constant_columns:\n",
        "    print(column)\n",
        "\n",
        "#Effect\n",
        "X_train.drop(constant_columns,axis=1, inplace=True)\n",
        "X_test.drop(constant_columns,axis=1, inplace=True)\n",
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNHIsRefoKed",
        "outputId": "ce055617-07f0-4372-ff8b-7ff1450cfabb"
      },
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True False False False False False False False  True\n",
            "  True False False False False  True  True  True  True False False False\n",
            " False False False]\n",
            "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
            "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst'],\n",
            "      dtype='object')\n",
            "Number of columns to be eliminated:  17\n",
            "smoothness_mean\n",
            "compactness_mean\n",
            "concavity_mean\n",
            "concave points_mean\n",
            "symmetry_mean\n",
            "fractal_dimension_mean\n",
            "radius_se\n",
            "smoothness_se\n",
            "compactness_se\n",
            "concavity_se\n",
            "concave points_se\n",
            "smoothness_worst\n",
            "compactness_worst\n",
            "concavity_worst\n",
            "concave points_worst\n",
            "symmetry_worst\n",
            "fractal_dimension_worst\n",
            "[ True  True  True  True  True  True  True  True  True  True]\n",
            "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
            "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst'],\n",
            "      dtype='object')\n",
            "Number of columns to be eliminated:  0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
              "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)\n",
        "# print_metrics(y_test, rf_preds, \"Random Forest\")\n",
        "cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSA4pJ5qevGY",
        "outputId": "13cfbfbd-7e93-4295-b8fe-e967bf459f34"
      },
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9484268125854994"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_preds = dt.predict(X_test)\n",
        "# print_metrics(y_test, dt_preds, \"Decision Tree\")\n",
        "cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgLZ8jMYmz2k",
        "outputId": "d2aef854-fb7f-4927-cdc6-ab452455acac"
      },
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9155950752393981"
            ]
          },
          "metadata": {},
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Employ Logistic regression classification\n",
        "\n",
        "lr = lr = LogisticRegression(solver='liblinear')\n",
        "lr.fit(X_train, y_train)\n",
        "lr_preds = lr.predict(X_test)\n",
        "# print_metrics(y_test, lr_preds, \"Logistic Regression\")\n",
        "cross_val_score(lr, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcV4Q2bOp5Pn",
        "outputId": "21fbcdbb-9f7c-48ba-d0aa-a40fe22821c3"
      },
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9320109439124487"
            ]
          },
          "metadata": {},
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vc = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('lr', lr)], voting='soft')\n",
        "cv_scores = cross_val_score(vc, X_train, y_train, cv=5, scoring='accuracy')\n",
        "cross_val_score(vc, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_LPFpQVm3xL",
        "outputId": "15ff6113-3c29-4640-f71c-6d156cb69279"
      },
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9460738714090289"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kUZgUoR8hMRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
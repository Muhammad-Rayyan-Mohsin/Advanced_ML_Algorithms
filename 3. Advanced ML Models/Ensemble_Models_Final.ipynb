{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "n-QxxuW90bO_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df_Original = df.copy()\n",
        "df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "gVyWhKOi0i2W"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LEvDmfVWaCh",
        "outputId": "ab7d7e59-2018-4ac7-e502-b2b4817086f0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    object \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['diagnosis'] = le.fit_transform(df['diagnosis'])"
      ],
      "metadata": {
        "id": "osiHWCU81Ans"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['texture_se', 'symmetry_se', 'fractal_dimension_se'], axis=1, inplace=True)\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "s8Nkf6YBIng5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "# Function to print all relevant metrics\n",
        "def print_metrics(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Initialize and fit the XGBoost model\n",
        "xgb_model = XGBClassifier(n_estimators=3, max_depth=4, learning_rate=0.8, objective='binary:logistic')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "print_metrics(y_test, xgb_preds, \"XGBoost\")\n",
        "\n",
        "# Initialize and fit the LightGBM model\n",
        "lgbm_model = LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "lgbm_preds = lgbm_model.predict(X_test)\n",
        "lgbm_preds\n",
        "print_metrics(y_test, lgbm_preds, \"LightGBM\")\n",
        "\n",
        "# Initialize and fit the Bagging Classifier model\n",
        "base_classifier = LogisticRegression(solver='liblinear')\n",
        "bagging_classifier = BaggingClassifier(base_estimator=base_classifier, n_estimators=10, random_state=123)\n",
        "cv_scores = cross_val_score(bagging_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(f'Bagging Classifier Mean Accuracy (Cross-Validation): {mean_cv_score:.2f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaG1HQVX1SqC",
        "outputId": "850608bb-c73b-45a9-9ac4-8c07032fb283"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Metrics:\n",
            "Accuracy: 0.9591\n",
            "Precision: 0.9516\n",
            "Recall: 0.9365\n",
            "F1 Score: 0.9440\n",
            "Confusion Matrix:\n",
            "[[105   3]\n",
            " [  4  59]]\n",
            "------------------------------\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 149, number of negative: 249\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3579\n",
            "[LightGBM] [Info] Number of data points in the train set: 398, number of used features: 27\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.374372 -> initscore=-0.513507\n",
            "[LightGBM] [Info] Start training from score -0.513507\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Metrics:\n",
            "Accuracy: 0.9591\n",
            "Precision: 0.9375\n",
            "Recall: 0.9524\n",
            "F1 Score: 0.9449\n",
            "Confusion Matrix:\n",
            "[[104   4]\n",
            " [  3  60]]\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Mean Accuracy (Cross-Validation): 0.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**- Blending**\n",
        "\n",
        "---\n",
        "**Stacked Model**: An ensemble of models in which the meta-model is trained on out-of-fold predictions made by the base models during k-fold cross validation.\n",
        "\n",
        "**Blended Model**: An ensemble of models in which the meta-model is trained on predictions made by the base models on a holdout dataset (e.g., the validation dataset).\n"
      ],
      "metadata": {
        "id": "2c1I9JlMiMSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=12345)"
      ],
      "metadata": {
        "id": "VM5r4i0LdbZ5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [('dtc', DecisionTreeClassifier()),\n",
        "        ('gnb', ExtraTreesClassifier()),\n",
        "        ('ada', AdaBoostClassifier()),\n",
        "        ('rf', RandomForestClassifier())]"
      ],
      "metadata": {
        "id": "rgTBWlM0VVhg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_models(models, X_train, X_valid, y_train, y_valid):\n",
        "\n",
        "    #Create variable in which to store predictions for meta-model.\n",
        "    preds_for_meta = []\n",
        "\n",
        "    #Loop through models in model list.\n",
        "    for name, model in tqdm(models):\n",
        "\n",
        "        #Fit model and obtain predictions.\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "        #Obtain base moedl roc score.\n",
        "        roc_base = roc_auc_score(y_valid, pred)\n",
        "\n",
        "        print(f'{model} score: {roc_base}')\n",
        "\n",
        "        #Reshape prediction into single-column matrix.\n",
        "        pred = pred.reshape(len(pred), 1)\n",
        "\n",
        "        #Append prediction to varible for meta-model.\n",
        "        preds_for_meta.append(pred)\n",
        "\n",
        "    #Create 2D array from predictions.\n",
        "    meta_features = np.hstack(preds_for_meta)\n",
        "\n",
        "    #Define blender for model.\n",
        "    meta_model = xgb.XGBClassifier(n_estimators=7000,\n",
        "                                 #tree_method='gpu_hist',\n",
        "                                 #gpu_id = 0,\n",
        "                                 random_state = 5,\n",
        "                                 learning_rate=.03)\n",
        "\n",
        "    #Fit meta model on predictions from base models.\n",
        "    meta_model.fit(meta_features, y_valid.values.ravel(),\n",
        "                 verbose=False,\n",
        "                 eval_set=[(meta_features, y_valid.values.ravel())],\n",
        "                 eval_metric='auc',\n",
        "                 early_stopping_rounds=300)\n",
        "\n",
        "    print(f'Meta AUC: {roc_auc_score(y_valid, meta_model.predict_proba(meta_features)[:, 1])}')\n",
        "\n",
        "    return meta_model\n",
        "\n",
        "def meta_predict(models, meta_model, X_test, threshold=0.5):\n",
        "    preds_for_meta = []\n",
        "\n",
        "    for name, model in tqdm(models):\n",
        "        pred = model.predict(X_test)\n",
        "\n",
        "        pred = pred.reshape(len(pred), 1)\n",
        "\n",
        "        preds_for_meta.append(pred)\n",
        "\n",
        "    meta_features = np.hstack(preds_for_meta)\n",
        "\n",
        "    meta_preds = meta_model.predict_proba(meta_features)[:, 1]\n",
        "\n",
        "    binary_preds = (meta_preds >= threshold).astype(int)\n",
        "\n",
        "    return binary_preds\n"
      ],
      "metadata": {
        "id": "leCKefu2aOuM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_model = fit_models(models, X_train, X_valid, y_train, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXdP1DQ9aYPF",
        "outputId": "34e1d51b-6e33-4a26-be4b-d8e27733d646"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier() score: 0.8574168797953964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 2/4 [00:00<00:00, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExtraTreesClassifier() score: 0.9879582267689685\n",
            "AdaBoostClassifier() score: 0.9731457800511509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier() score: 0.9757033248081841\n",
            "Meta AUC: 0.9995737425404945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_pred = meta_predict(models, meta_model, X_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muD02damafeM",
        "outputId": "a985bbe1-994d-4348-bfea-a152f4da130c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 108.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAjARc8Db-Fo",
        "outputId": "9221955a-de5f-443d-abd8-5800dbbe2a65"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Classifier\n",
        "\n",
        "---\n",
        "- Using RF, LR and DT\n"
      ],
      "metadata": {
        "id": "VfxHcqi9xnCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # with the following function we can select highly correlated features\n",
        "# # it will remove the first feature that is correlated with anything other feature\n",
        "\n",
        "# def correlation(dataset, threshold):\n",
        "#     col_corr = set()  # Set of all the names of correlated columns\n",
        "#     corr_matrix = dataset.corr()\n",
        "#     for i in range(len(corr_matrix.columns)):\n",
        "#         for j in range(i):\n",
        "#             if corr_matrix.iloc[i, j] > threshold: # we are interested in absolute coeff value\n",
        "#                 colname = corr_matrix.columns[i]  # getting the name of column\n",
        "#                 col_corr.add(colname)\n",
        "#     return col_corr\n",
        "\n",
        "# corr_features = correlation(X_train, 0.7)\n",
        "\n",
        "# print(len(set(corr_features)))\n",
        "\n",
        "# print(corr_features)\n",
        "\n",
        "# #Effect\n",
        "# X_train.drop(corr_features,axis=1, inplace=True)\n",
        "# X_test.drop(corr_features,axis=1, inplace=True)\n",
        "# X_train.columns\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thres=VarianceThreshold(threshold=0.7)\n",
        "var_thres.fit(X_train)\n",
        "print(var_thres.get_support())\n",
        "sum(var_thres.get_support())\n",
        "selected_features = X_train.columns[var_thres.get_support()]\n",
        "print(selected_features)\n",
        "\n",
        "constant_columns = [column for column in X_train.columns\n",
        "                    if column not in X_train.columns[var_thres.get_support()]]\n",
        "\n",
        "print(\"Number of columns to be eliminated: \", len(constant_columns))\n",
        "for column in constant_columns:\n",
        "    print(column)\n",
        "\n",
        "#Effect\n",
        "X_train.drop(constant_columns,axis=1, inplace=True)\n",
        "X_test.drop(constant_columns,axis=1, inplace=True)\n",
        "X_train.columns\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thres=VarianceThreshold(threshold=0.7)\n",
        "var_thres.fit(X_train)\n",
        "print(var_thres.get_support())\n",
        "sum(var_thres.get_support())\n",
        "selected_features = X_train.columns[var_thres.get_support()]\n",
        "print(selected_features)\n",
        "\n",
        "constant_columns = [column for column in X_train.columns\n",
        "                    if column not in X_train.columns[var_thres.get_support()]]\n",
        "\n",
        "print(\"Number of columns to be eliminated: \", len(constant_columns))\n",
        "for column in constant_columns:\n",
        "    print(column)\n",
        "\n",
        "#Effect\n",
        "X_train.drop(constant_columns,axis=1, inplace=True)\n",
        "X_test.drop(constant_columns,axis=1, inplace=True)\n",
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNHIsRefoKed",
        "outputId": "612ba2f4-b817-4a70-e758-e4ad519b3a46"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True  True  True False False False False False False False  True\n",
            "  True False False False False  True  True  True  True False False False\n",
            " False False False]\n",
            "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
            "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst'],\n",
            "      dtype='object')\n",
            "Number of columns to be eliminated:  17\n",
            "smoothness_mean\n",
            "compactness_mean\n",
            "concavity_mean\n",
            "concave points_mean\n",
            "symmetry_mean\n",
            "fractal_dimension_mean\n",
            "radius_se\n",
            "smoothness_se\n",
            "compactness_se\n",
            "concavity_se\n",
            "concave points_se\n",
            "smoothness_worst\n",
            "compactness_worst\n",
            "concavity_worst\n",
            "concave points_worst\n",
            "symmetry_worst\n",
            "fractal_dimension_worst\n",
            "[ True  True  True  True  True  True  True  True  True  True]\n",
            "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
            "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst'],\n",
            "      dtype='object')\n",
            "Number of columns to be eliminated:  0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
              "       'perimeter_se', 'area_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)\n",
        "# print_metrics(y_test, rf_preds, \"Random Forest\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSA4pJ5qevGY",
        "outputId": "53e060dc-a5dd-44a6-cb51-73007f7ad1c6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       108\n",
            "           1       1.00      0.97      0.98        63\n",
            "\n",
            "    accuracy                           0.99       171\n",
            "   macro avg       0.99      0.98      0.99       171\n",
            "weighted avg       0.99      0.99      0.99       171\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9437209302325582"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_preds = dt.predict(X_test)\n",
        "# print_metrics(y_test, dt_preds, \"Decision Tree\")\n",
        "print(classification_report(y_test, dt_preds))\n",
        "cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgLZ8jMYmz2k",
        "outputId": "2b09e165-3953-42bb-df7e-d24ad62b6d8d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       108\n",
            "           1       0.95      0.98      0.97        63\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.98      0.98       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9132147742818058"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Employ Logistic regression classification\n",
        "\n",
        "lr = lr = LogisticRegression(solver='liblinear')\n",
        "lr.fit(X_train, y_train)\n",
        "lr_preds = lr.predict(X_test)\n",
        "# print_metrics(y_test, lr_preds, \"Logistic Regression\")\n",
        "print(classification_report(y_test, lr_preds))\n",
        "cross_val_score(lr, X_train, y_train, cv=5, scoring='accuracy').mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcV4Q2bOp5Pn",
        "outputId": "8d9f6df5-0361-4b0d-e4d6-ddbd4f8f82a8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       108\n",
            "           1       0.97      0.95      0.96        63\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9320109439124487"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vc = VotingClassifier(estimators=[('rf', rf), ('dt', dt), ('lr', lr)], voting='soft')\n",
        "cv_scores = cross_val_score(vc, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(classification_report(y_test, vc.fit(X_train, y_train).predict(X_test)))\n",
        "cross_val_score(vc, X_train, y_train, cv=5, scoring='accuracy').mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_LPFpQVm3xL",
        "outputId": "4873834f-9d8e-4f32-a1a5-3c0207b7f803"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       108\n",
            "           1       1.00      1.00      1.00        63\n",
            "\n",
            "    accuracy                           1.00       171\n",
            "   macro avg       1.00      1.00      1.00       171\n",
            "weighted avg       1.00      1.00      1.00       171\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.94374829001368"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - **Support Vector Machine (SVM):**"
      ],
      "metadata": {
        "id": "-MAdXoKITy-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "precision = precision_score(y_test, pred)\n",
        "recall = recall_score(y_test, pred)\n",
        "f1 = f1_score(y_test, pred)\n",
        "# accuracy\n",
        "print(classification_report(y_test, pred))\n",
        "cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldLhjKhpUEaI",
        "outputId": "69c2807c-de5d-4d37-c6fc-dc3ece15f34e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       108\n",
            "           1       0.98      0.94      0.96        63\n",
            "\n",
            "    accuracy                           0.97       171\n",
            "   macro avg       0.97      0.96      0.97       171\n",
            "weighted avg       0.97      0.97      0.97       171\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9319562243502052"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUr_rUysULcx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}